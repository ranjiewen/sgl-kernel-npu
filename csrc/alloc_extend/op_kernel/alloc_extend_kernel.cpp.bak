// Licensed under the BSD 3-Clause License  (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/* include file of ascendc */
#include "kernel_operator.h"
#include "../op_host/alloc_extend_tiling.h"
/* tensor num for each queue */
constexpr int32_t BUFFER_NUM = 1;
constexpr int64_t byteAlign = 32;
__aicore__ inline uint32_t ceil_div(int64_t a, int64_t b)
{
    if (b == 0)
        return a;
    return (a + b - 1) / b;
}

class KernelAllocExtent {
public:
    __aicore__ inline KernelAllocExtent() {}
    __aicore__ inline void Init(GM_ADDR pre_lens_in, GM_ADDR seq_lens_in, GM_ADDR last_loc_in,
        GM_ADDR free_pages_in, GM_ADDR out_indices_in, GM_ADDR values_in, 
        GM_ADDR workspace_in, GM_ADDR tiling_gm_in) {
        auto tiling_gm = reinterpret_cast<__gm__ sglang::npu_kernel::AllocExtendTilingData *>(tiling_gm_in);
        this->batch_size = tiling_gm->batch_size;
        this->page_size = tiling_gm->page_size;
        this->used_core_num = tiling_gm->used_core_num;
        this->total_extend_tokens = tiling_gm->total_extend_tokens;
        this->core_id = AscendC::GetBlockIdx();
        this->block_num = AscendC::GetBlockNum();
        
        this->pre_lens_gm.SetGlobalBuffer((__gm__ int64_t*)pre_lens_in, this->batch_size);  // 全量数据，有效部分sum
        this->seq_lens_gm.SetGlobalBuffer((__gm__ int64_t*)seq_lens_in, this->batch_size);
        this->last_loc_gm.SetGlobalBuffer((__gm__ int64_t*)last_loc_in, this->batch_size);
        this->free_pages_gm.SetGlobalBuffer((__gm__ int64_t*)free_pages_in);
        this->out_indices_gm.SetGlobalBuffer((__gm__ int64_t*)out_indices_in, this->total_extend_tokens);
        
        this->total_size_aligned = ceil_div(this->batch_size * sizeof(int64_t), byteAlign) * byteAlign;
        this->pipe.InitBuffer(this->pre_lens_que, BUFFER_NUM, this->total_size_aligned); // align
        this->pipe.InitBuffer(this->seq_lens_que, BUFFER_NUM, this->total_size_aligned);

        int32_t data_size = ceil_div(this->batch_size * sizeof(int32_t), byteAlign) * byteAlign;
        this->pipe.InitBuffer(tmp_pre_lens_que, data_size);
        this->pipe.InitBuffer(tmp_seq_lens_que, data_size);
        this->pipe.InitBuffer(tmp_out_indices_que, data_size);
        this->pipe.InitBuffer(tmp_que, 1024); 
        this->pipe.InitBuffer(work_que, 128); // 单位字节

        AscendC::printf("cur cored_id, block_num: %d, %d, %d, %d\n", this->core_id, this->block_num, this->batch_size, this->total_size_aligned);
    }
    __aicore__ inline void Process() {
        for (int32_t task_id = this->core_id; task_id < this->batch_size; task_id += this->block_num) {
            CopyIn();
            Compute(task_id);
            CopyOut();
        }
    }
private:
    __aicore__ inline void CopyIn() {
        // pad对齐拷贝
        AscendC::LocalTensor<int64_t> pre_lens_ub = this->pre_lens_que.AllocTensor<int64_t>();
        AscendC::DataCopyExtParams copyParams{1, static_cast<uint32_t>(this->batch_size * sizeof(int64_t)), 0, 0, 0}; // 结构体DataCopyExtParams最后一个参数是rsv保留位
        AscendC::DataCopyPadExtParams<int64_t> padParams{true, 0, 0, 0};
        AscendC::DataCopyPad(pre_lens_ub, this->pre_lens_gm, copyParams, padParams); // 从GM->VECIN搬运40Bytes
        this->pre_lens_que.EnQue(pre_lens_ub);
        AscendC::DumpTensor(pre_lens_gm, 0, this->batch_size); // 未生效
        AscendC::DumpTensor(pre_lens_ub, 5, this->batch_size); // 未生效
        
        AscendC::LocalTensor<int64_t> seq_lens_ub = this->seq_lens_que.AllocTensor<int64_t>();
        AscendC::DataCopyPad(seq_lens_ub, this->seq_lens_gm, copyParams, padParams);
        this->seq_lens_que.EnQue(seq_lens_ub);
        AscendC::DumpTensor(seq_lens_ub, 5, this->batch_size);
        AscendC::DumpAccChkPoint(seq_lens_ub, 0, 0, 1);
    }

    __aicore__ inline void Compute(int64_t task_id) {
        AscendC::LocalTensor<int64_t> pre_lens_ub = pre_lens_que.DeQue<int64_t>();
        AscendC::LocalTensor<int64_t> seq_lens_ub = seq_lens_que.DeQue<int64_t>();
        
        AscendC::LocalTensor<int32_t> tmp_buf_src1 = tmp_seq_lens_que.Get<int32_t>(); // 元素个数
        AscendC::LocalTensor<int32_t> tmp_buf_src2 = tmp_pre_lens_que.AllocTensor<int32_t>();
        AscendC::printf("==>seq_lens_ub: %d \n", seq_lens_ub.GetValue(0));

        AscendC::Cast(tmp_buf_src1, seq_lens_ub, AscendC::RoundMode::CAST_NONE, this->batch_size);
        AscendC::Cast(tmp_buf_src2, pre_lens_ub, AscendC::RoundMode::CAST_NONE, this->batch_size);
        // extend_lens = seq_lens - pre_lens
        AscendC::Sub(tmp_buf_src1, tmp_buf_src1, tmp_buf_src2, this->batch_size);
        AscendC::printf("!!!extend_lens: %d \n", tmp_buf_src1.GetValue(0));
        // output_start_loc = tl.sum(extend_lens) - extend_len
        // AscendC::LocalTensor<int32_t> tmp_reduce_buf = tmp_que.GetWithOffset<int32_t>(4, this->total_size_aligned);
        // AscendC::LocalTensor<int32_t> shared_tmp_buf = work_que.AllocTensor<int32_t>();
        // AscendC::ReduceSum<int32_t>(tmp_reduce_buf, tmp_buf_src2, shared_tmp_buf, task_id);  // 当前task之前的和
        // int32_t extend_lens_sum = tmp_reduce_buf.GetValue(0);
        int32_t extend_lens_sum = 0;
        for (int i = 0; i < task_id + 1; i++) {
            extend_lens_sum = extend_lens_sum + tmp_buf_src2.GetValue(i);
            AscendC::printf("i, value: %d, %d \n", i, tmp_buf_src2.GetValue(i));
        }
        // get value seqlen, prelen->extend_len
        int32_t cur_seqlen = this->seq_lens_gm.GetValue(task_id);
        int32_t cur_prelen = this->pre_lens_gm.GetValue(task_id);
        int32_t cur_extend_len = cur_seqlen - cur_prelen;
        int32_t output_start_loc = extend_lens_sum - cur_extend_len;
        AscendC::printf("cur_seqlen, cur_prelen, extend_lens_sum, cur_extend_len: %d, %d, %d %d \n", cur_seqlen, cur_prelen, extend_lens_sum, cur_extend_len);
        // seq_lens, pre_lens // page_size
        
    }
    __aicore__ inline void CopyOut() {

    }
private:
    AscendC::TPipe pipe;
    AscendC::TBuf<AscendC::TPosition::VECCALC> tmp_que, work_que;
    AscendC::TBuf<AscendC::TPosition::VECCALC> tmp_pre_lens_que;
    AscendC::TBuf<AscendC::TPosition::VECCALC> tmp_seq_lens_que;
    AscendC::TBuf<AscendC::TPosition::VECCALC> tmp_out_indices_que;

    AscendC::TQue<AscendC::TPosition::VECIN, 1> pre_lens_que;  // 1 for que depth
    AscendC::TQue<AscendC::TPosition::VECIN, 1> seq_lens_que;
    AscendC::GlobalTensor<int64_t> pre_lens_gm;
    AscendC::GlobalTensor<int64_t> seq_lens_gm;
    AscendC::GlobalTensor<int64_t> last_loc_gm;
    AscendC::GlobalTensor<int64_t> free_pages_gm;
    AscendC::GlobalTensor<int64_t> out_indices_gm;
    AscendC::GlobalTensor<int64_t> values_gm;

    int32_t core_id;
    int32_t block_num;
    int32_t batch_size;
    int32_t total_size_aligned;
    int32_t page_size;
    int32_t used_core_num;
    int32_t total_extend_tokens;
};


extern "C" __global__ __aicore__ void alloc_extend(GM_ADDR pre_lens_in, GM_ADDR seq_lens_in, GM_ADDR last_loc_in,
    GM_ADDR free_pages_in, GM_ADDR out_indices_in, GM_ADDR values_in, GM_ADDR workspace_in, GM_ADDR tiling_gm_in)
{
    KernelAllocExtent op;
    op.Init(pre_lens_in, seq_lens_in, last_loc_in, free_pages_in, out_indices_in, values_in, workspace_in, tiling_gm_in);
    op.Process();
}

